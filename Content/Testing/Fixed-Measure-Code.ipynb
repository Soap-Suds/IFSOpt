{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.linalg import LinAlgError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transformation_matrix(M: torch.Tensor) -> bool:\n",
    "    \"\"\"\n",
    "    Validates a 3x3 matrix (torch.Tensor) representing an affine transformation on R^2.\n",
    "\n",
    "    Checks:\n",
    "    1. Affine on R^2: last row is [0, 0, 1]\n",
    "    2. Contraction: largest singular value of A < 1\n",
    "    3. Invertibility: det(M) != 0\n",
    "    4. Fixed point in [0, 1]^2\n",
    "\n",
    "    Args:\n",
    "        M (torch.Tensor): 3x3 matrix\n",
    "\n",
    "    Returns:\n",
    "        bool: True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    if not isinstance(M, torch.Tensor) or M.shape != (3, 3):\n",
    "        raise ValueError(\"Input must be a 3x3 torch.Tensor.\")\n",
    "\n",
    "    # 1. Affine check\n",
    "    if not torch.allclose(M[2, :], torch.tensor([0.0, 0.0, 1.0], dtype=M.dtype, device=M.device)):\n",
    "        return False\n",
    "\n",
    "    # 2. Contraction check\n",
    "    A = M[:2, :2]\n",
    "    try:\n",
    "        singular_values = torch.linalg.svdvals(A)\n",
    "    except Exception:\n",
    "        return False\n",
    "    if torch.max(singular_values) >= 1.0:\n",
    "        return False\n",
    "\n",
    "    # 3. Invertibility\n",
    "    if torch.isclose(torch.det(M), torch.tensor(0.0, dtype=M.dtype, device=M.device)):\n",
    "        return False\n",
    "\n",
    "    # 4. Fixed point in [0, 1]^2\n",
    "    I = torch.eye(2, dtype=M.dtype, device=M.device)\n",
    "    b = M[:2, 2]\n",
    "    try:\n",
    "        fixed_point = torch.linalg.solve(A - I, -b)\n",
    "    except Exception:\n",
    "        return False\n",
    "    x, y = fixed_point.tolist()\n",
    "    if not (0 <= x <= 1 and 0 <= y <= 1):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedMeasure:\n",
    "    \"\"\"\n",
    "    Computes the fixed measure of an Iterated Function System (IFS) for a given\n",
    "    initial measure using the Banach fixed-point theorem.\n",
    "    This version is optimized for GPU (CUDA) execution if available.\n",
    "    \"\"\"\n",
    "    def __init__(self, F: List[torch.Tensor], nu: torch.Tensor, p: torch.Tensor = None, eps: float = 1e-4):\n",
    "        \"\"\"\n",
    "        Initializes the FixedMeasure system.\n",
    "\n",
    "        Args:\n",
    "            F (List[torch.Tensor]): A list of 3x3 invertible matrices representing the\n",
    "                                     affine transformations f(x) = Ax + b.\n",
    "            nu (torch.Tensor): The initial measure on a d x d pixel grid of the unit square.\n",
    "            p (torch.Tensor, optional): A probability vector of length n. Defaults to uniform.\n",
    "            eps (float): The convergence threshold for the Wasserstein-infinity distance.\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Validation (on CPU) ---\n",
    "        if not all(check_transformation_matrix(f) for f in F):\n",
    "            raise ValueError(\"All transformations in F must be valid IFS maps.\")\n",
    "        if not torch.isclose(p.sum(), torch.tensor(1.0, dtype=p.dtype, device=p.device)):\n",
    "            raise ValueError(\"Probability vector p must sum to 1.\")\n",
    "        \n",
    "        # Set the computation device to CUDA if available, otherwise CPU.\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "\n",
    "        # Move input matrices to the selected device\n",
    "        self.F = [m.to(torch.float32).to(self.device) for m in F]\n",
    "        self.n = len(F)\n",
    "        self.eps = eps\n",
    "\n",
    "        if p is None:\n",
    "            # Default to a uniform probability vector if not provided\n",
    "            self.p = torch.full((self.n,), 1.0 / self.n, dtype=torch.float32, device=self.device)\n",
    "        else:\n",
    "            assert p.shape[0] == self.n, f\"Probability vector p must have length {self.n}.\"\n",
    "            assert abs(p.sum().item() - 1.0) < 1e-6, \"Probabilities in p must sum to 1.\"\n",
    "            self.p = p.to(torch.float32).to(self.device)\n",
    "        \n",
    "        # The measure nu is defined on a d x d grid\n",
    "        assert nu.dim() == 2 and nu.shape[0] == nu.shape[1], \"nu must be a square tensor.\"\n",
    "        self.d = nu.shape[0]\n",
    "\n",
    "        # Raise an error if d is not a power of 2\n",
    "        if not (self.d & (self.d - 1) == 0 and self.d != 0):\n",
    "            raise ValueError(f\"d = {self.d} is not a power of 2. Please use a power-of-2 grid size.\")\n",
    "\n",
    "        # Reshape initial measure for grid_sample (N, C, H, W), normalize, and move to device\n",
    "        self.mu = nu.reshape(1, 1, self.d, self.d).to(self.device)\n",
    "        self.mu = self.mu / self.mu.sum()\n",
    "\n",
    "        # Precompute transformed grids and Jacobians on the selected device\n",
    "        self.Maps = self._precompute_maps()\n",
    "\n",
    "    def _precompute_maps(self) -> List[Tuple[torch.Tensor, float]]:\n",
    "        \"\"\"\n",
    "        Precomputes the transformed sampling grids and Jacobian determinants for each map.\n",
    "        This is a one-time setup cost to accelerate the iterative solve method.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[torch.Tensor, float]]: A list where each element is a tuple containing\n",
    "                                              the transformed grid for grid_sample and the\n",
    "                                              absolute Jacobian determinant.\n",
    "        \"\"\"\n",
    "        maps_data = []\n",
    "\n",
    "        # Create a base grid of coordinates on the selected device.\n",
    "        y_coords = torch.linspace(0, 1, self.d, dtype=torch.float32, device=self.device)\n",
    "        x_coords = torch.linspace(0, 1, self.d, dtype=torch.float32, device=self.device)\n",
    "        grid_y, grid_x = torch.meshgrid(y_coords, x_coords, indexing='ij')\n",
    "        \n",
    "        grid_flat = torch.stack([grid_x, grid_y], dim=-1).reshape(-1, 2)\n",
    "        grid_homogeneous = torch.cat([grid_flat, torch.ones(self.d * self.d, 1, device=self.device)], dim=1)\n",
    "\n",
    "        for f_matrix in self.F:\n",
    "            A = f_matrix[:2, :2]\n",
    "            jac_det = torch.det(A).abs().item()\n",
    "\n",
    "            f_inv = torch.inverse(f_matrix)\n",
    "            transformed_homogeneous = torch.matmul(grid_homogeneous, f_inv.t())\n",
    "            transformed_flat = transformed_homogeneous[:, :2] / transformed_homogeneous[:, 2].unsqueeze(1)\n",
    "\n",
    "            normalized_transformed_grid = 2 * transformed_flat - 1\n",
    "            final_grid = normalized_transformed_grid.reshape(1, self.d, self.d, 2)\n",
    "            \n",
    "            maps_data.append((final_grid, jac_det))\n",
    "            \n",
    "        return maps_data\n",
    "\n",
    "    def push_forward(self, mu: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Computes the weighted push-forward measure: mu_{t+1} = Î£ p_i * f_i#(mu_t).\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor): Current measure, shape (1, 1, d, d).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The next measure in the iteration.\n",
    "        \"\"\"\n",
    "        mu_next = torch.zeros_like(mu, device=self.device)\n",
    "\n",
    "        for i, (transformed_grid, jac_det) in enumerate(self.Maps):\n",
    "            pushed_mu_component = torch.nn.functional.grid_sample(\n",
    "                mu,\n",
    "                transformed_grid,\n",
    "                mode='bilinear',\n",
    "                padding_mode='zeros',\n",
    "                align_corners=True\n",
    "            )\n",
    "\n",
    "            if jac_det > 1e-9:\n",
    "                pushed_mu_component /= jac_det\n",
    "            \n",
    "            # Weight the pushforward component by its probability\n",
    "            mu_next += self.p[i] * pushed_mu_component\n",
    "        \n",
    "        # Re-normalize to counteract any minor mass loss from interpolation/padding\n",
    "        mu_next /= mu_next.sum()\n",
    "        \n",
    "        return mu_next\n",
    "\n",
    "    def wasserstein_inf(self, mu1: torch.Tensor, mu2: torch.Tensor) -> float:\n",
    "        \"\"\"\n",
    "        Computes an approximation of the Wasserstein-infinity distance.\n",
    "\n",
    "        Args:\n",
    "            mu1, mu2 (torch.Tensor): The two measures to compare.\n",
    "\n",
    "        Returns:\n",
    "            float: The approximated W_infinity distance.\n",
    "        \"\"\"\n",
    "        return torch.abs(mu1 - mu2).max().item()\n",
    "\n",
    "    def solve(self, max_iterations: int = 1000, min_iterations: int = 100) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Iterates the pushforward operation until the measure converges to a fixed point.\n",
    "\n",
    "        Args:\n",
    "            max_iterations (int): Maximum number of iterations to perform.\n",
    "            min_iterations (int): Minimum number of iterations before checking for convergence.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final, converged measure.\n",
    "        \"\"\"\n",
    "        current_mu = self.mu.clone()\n",
    "        \n",
    "        for t in range(max_iterations):\n",
    "            next_mu = self.push_forward(current_mu)\n",
    "            w_inf = self.wasserstein_inf(current_mu, next_mu)\n",
    "            \n",
    "            print(f\"Iteration {t+1}, W_infinity = {w_inf:.2e}\")\n",
    "            \n",
    "            if abs(next_mu.sum().item() - 1.0) > 1e-9:\n",
    "                print(f\"Warning: Measure not properly normalized. Total mass = {next_mu.sum().item()}\")\n",
    "\n",
    "            if t + 1 >= min_iterations and w_inf < self.eps:\n",
    "                print(f\"Converged after {t+1} iterations!\")\n",
    "                return next_mu\n",
    "            \n",
    "            current_mu = next_mu\n",
    "        else:\n",
    "            print(f\"Maximum iterations ({max_iterations}) reached. Final W_infinity = {w_inf:.2e}\")\n",
    "            \n",
    "        return current_mu\n",
    "        \n",
    "    def visualize_measure(self, mu: torch.Tensor, title: str = \"Measure Visualization\"):\n",
    "        \"\"\"\n",
    "        Visualize the measure as a heatmap.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor): The measure to visualize (tensor on self.device).\n",
    "            title (str): Title for the plot.\n",
    "        \"\"\"\n",
    "        # Move the measure to the CPU and convert to a numpy array for plotting\n",
    "        mu_np = mu.cpu().squeeze().numpy()\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        # The extent is the unit square [0, 1] x [0, 1].\n",
    "        # Using 'gray_r' colormap for a traditional black-on-white fractal.\n",
    "        plt.imshow(mu_np, origin='lower', extent=[0, 1, 0, 1], cmap='gray_r')\n",
    "        plt.colorbar(label='Measure Density')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ca88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the affine transformations for the L-Shape fractal\n",
    "    sierpinski_matrices = [\n",
    "        torch.tensor([\n",
    "            [0.5, 0.0, 0.0],\n",
    "            [0.0, 0.5, 0.0],\n",
    "            [0.0, 0.0, 1.0]\n",
    "        ]),\n",
    "        torch.tensor([\n",
    "            [0.5, 0.0, 0.5],\n",
    "            [0.0, 0.5, 0.0],\n",
    "            [0.0, 0.0, 1.0]\n",
    "        ]),\n",
    "        torch.tensor([\n",
    "            [0.5, 0.0, 0.0],\n",
    "            [0.0, 0.5, 0.5],\n",
    "            [0.0, 0.0, 1.0]\n",
    "        ])\n",
    "    ]\n",
    "    \n",
    "    # Define the probability vector (uniform for this example)\n",
    "    p_vector = torch.tensor([1/3, 1/3, 1/3])\n",
    "\n",
    "    # Define the grid resolution and the initial measure (uniform)\n",
    "    d_resolution = 1024\n",
    "    initial_nu = torch.ones((d_resolution, d_resolution))\n",
    "\n",
    "    # Create the FixedMeasure instance\n",
    "    sierpinski_ifs = FixedMeasure(F=sierpinski_matrices, nu=initial_nu, p=p_vector, eps=1e-7)\n",
    "\n",
    "    # Solve for the fixed measure, running at least 100 iterations\n",
    "    final_sierpinski_measure = sierpinski_ifs.solve(max_iterations=200, min_iterations=50)\n",
    "\n",
    "    # Visualize the final measure\n",
    "    sierpinski_ifs.visualize_measure(\n",
    "        final_sierpinski_measure,\n",
    "        title=f\"L-Shape Fixed Measure (d={d_resolution})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10375e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
